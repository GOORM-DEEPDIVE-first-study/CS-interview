<aside>

개인별 질문 주제 : 각자 발표 주제와 참고하여 결정

- 김두현님: 공유자원과 임계구역, 문제 해결(스핀락, 세마포어, 뮤텍스, 모니터)
- 도준영님: 캐시, 캐시 관리 전략, 프로세스 생성 과정(fork)
- 성종민님: 페이징과 세그먼테이션
</aside>

# 질문 셋 1 - 메모리 관리

- 주제 제시

먼저 운영체제에서 메모리 관리를 어떻게 하는지 알고 계시나요? 메모리 관리의 기초부터 얘기해봅시다.

---

**Q1. 페이징이 없는 시스템에서는 어떻게 메모리가 관리될까요? 그럴 경우 어떤 문제가 발생할까요?**

페이징이 없는 시스템에서는 메모리를 **연속적인 공간(Contiguous Memory Allocation)** 으로 관리합니다. 프로세스는 물리 메모리 내에서 **하나의 연속된 블록**에 적재되어야 하므로, 시간이 지나며 메모리 사이에 **작은 빈 공간들이 흩어지게 되고**, 이로 인해 **외부 단편화(External Fragmentation)** 가 발생합니다.

결과적으로, 충분한 전체 메모리가 있어도 **하나의 큰 연속 공간이 부족해서** 새로운 프로세스를 적재하지 못하는 상황이 발생할 수 있습니다.

---

**Q1-1. `외부 단편화`란 무엇이고, 어떻게 발생하나요?**

**외부 단편화**는 전체적으로는 충분한 메모리가 있음에도 불구하고, **작은 조각들로 흩어져 있어서** 프로세스에게 할당할 수 없는 상황을 말합니다.

**외부 단편화**는 메모리 할당과 해제가 반복되면서 **작은 조각의 빈 공간들이 메모리 전체에 흩어져 생기는 현상**

입니다. 이러한 조각들은 **개별적으로는 작아서 쓸 수 없지만**, 합치면 큰 공간이 되기 때문에 낭비가 발생합니다. 즉, **전체적으로는 여유 공간이 있음에도 불구하고**, **연속된 큰 공간이 없어** 프로세스가 할당되지 못합니다.

---

**Q1-2. 그와 비슷하게 메모리에서 발생하는 문제로 `내부 단편화` 가 있는데 내부 단편화는 무엇이고, 어떻게 발생하나요?**

**내부 단편화**는 시스템이 **고정 크기의 메모리 블록을 할당**할 때 발생합니다.

만약 프로세스가 해당 블록보다 적은 메모리를 요구하면, **남은 공간이 사용되지 않고 낭비**됩니다. 예를 들어, 4KB 블록을 할당했지만 실제로 3.7KB만 썼다면, 나머지 0.3KB는 내부 단편화로 남게 됩니다.

---

**Q2. 그럼 `페이징(Paging)` 은 이러한 문제를 어떻게 해결할 수 있을까요?**

**페이징**은 메모리 공간을 **고정된 크기의 페이지(Page)** 로 나눠서 관리함으로써, **연속된 공간을 요구하지 않아 외부 단편화를 제거**합니다.

프로세스의 논리 메모리는 페이지 단위로 쪼개지고, 이 페이지들은 물리 메모리의 **임의의 프레임(Frame)** 에 적재될 수 있습니다.

따라서 전체 메모리가 조각나 있어도, 필요한 만큼만 각각의 프레임에 배치하면 되므로 **연속성의 제약이 사라집니다**.

---

**Q2-1. 페이징을 사용하면 외부 단편화와 내부 단편화가 모두 일어나지 않나요?**

페이징은 **외부 단편화는 제거**하지만, **내부 단편화는 여전히 발생할 수 있습니다.**

예를 들어, 페이지 크기가 4KB일 때, 마지막 페이지가 3.6KB만 사용된다면 **남은 0.4KB는 낭비**됩니다. 이런 식으로 각 페이지마다 마지막 페이지 단위에서 **작은 내부 단편화가 누적**될 수 있습니다.

---

**Q3. 좋아요.  운영체제가 논리 주소를 실제 물리 주소로 변환하는 과정을 아시는 만큼만 설명해주실 수 있나요?**

논리 주소는 보통 두 부분으로 나뉘어집니다:

- **페이지 번호(Page Number)**
- **오프셋(Offset)**

운영체제는 프로세스마다 관리되는 **페이지 테이블(Page Table)** 을 참조하여, 논리 주소의 페이지 번호에 해당하는 **프레임 번호(Frame Number)** 를 찾습니다.

그리고 해당 프레임의 시작 주소에 offset을 더해 최종 **물리 주소(Physical Address)** 를 계산합니다.

이 작업은 CPU 내부의 **MMU(Memory Management Unit)** 에서 수행됩니다.

---

**Q3-1**. 페이지 테이블은 어디에 저장되나요? 그리고 `TLB` 는 무엇이며, 어디에 위치하나요?

페이지 테이블은 보통 **메인 메모리(RAM)**에 저장됩니다. 하지만 메인 메모리에 접근하는 것은 **속도가 느리기 때문에**, CPU는 **TLB(Translation Lookaside Buffer)** 라는 **캐시 메모리**를 사용해 페이지 테이블의 일부를 저장하고 빠르게 접근합니다.

- **TLB**는 CPU 내부의 **MMU(Memory Management Unit)** 안에 있는 **고속 캐시 하드웨어**입니다.
- 최근에 사용된 페이지 번호와 해당 프레임 번호를 저장해두고, 주소 변환을 빠르게 처리합니다.
- TLB에 원하는 항목이 있으면 **TLB hit**, 없으면 **TLB miss**로 메인 메모리의 페이지 테이블에 접근합니다.

# 질문 셋 2 - 공유 자원과 동기화

- 주제 제시

멀티 스레드 환경에서 공유 자원과 동기화에 대해서 얘기해봅시다. 멀티 스레드로 공유 카운터를 업데이트하는 시스템을 설계하고 있다고 생각해주세요.

---

**Q1. `임계 구역(critical section)` 이 무엇이고, 이 주제에서 왜 중요한가요?**

임계 구역은 변수나 파일과 같은 공유 자원에 액세스하는 코드 블록으로, **공유 자원 접근 순서에 따라 실행 결과가 달라지는 프로그램의 영역**입니다.

여러 스레드가 임계 구역을 동시에 접근해서는 안 됩니다. 두 스레드가 동기화 없이 공유 카운터를 동시에 수정하는 경쟁 조건이 발생하면, 잘못된 결과 값이 만들어질 수 있으므로 중요합니다.

---

**Q2. 임계 구역의 상호 배제를 보장하기 위해 일반적으로 사용하는 방법은 어떤 게 있나요? 아시는 걸로 어떤 게 있는지 나열해보시겠어요?**

임계 구역의 상호 배제를 보장하기 위한 방법으로 아래 것들이 있습니다.

1. 뮤텍스 (Mutex, Mutual Exclusion)
2. 세마포어 (Semaphore)
3. 스핀 락 (Spinlock)
4. 모니터 (Monitor)
5. 인터럽트 막기 (커널 레벨 코드에서 사용됨)

---

**Q3**. `뮤텍스(mutex)` 에 대해서 먼저 얘기해볼께요. 뮤텍스가 어떤 것이고 어떻게 작동하는지 알려주실 수 있나요? 
Mutex는 **공유 자원에 동시에 접근하지 못하도록 막아주는 동기화 기법**입니다. 여러 개의 스레드나 프로세스가 동시에 하나의 자원(예: 변수, 파일, 메모리)에 접근하려고 할 때, 데이터의 일관성이 깨지거나 예기치 않은 동작이 발생할 수 있습니다. 이를 방지하기 위해 **한 시점에 하나의 스레드만 자원에 접근하도록 제한**하는 것이 Mutex의 역할입니다.

**작동 방식은 다음과 같습니다:**

1. **Lock(잠금)**: 스레드가 공유 자원을 사용하기 전에 Mutex를 획득합니다. 이미 다른 스레드가 잠금을 가지고 있다면, 현재 스레드는 **대기**하게 됩니다.
2. **Critical Section(임계 영역)**: Mutex를 획득한 스레드는 안전하게 공유 자원을 사용할 수 있습니다.
3. **Unlock(잠금 해제)**: 작업이 끝나면 Mutex를 해제하여 다른 스레드가 자원을 사용할 수 있도록 합니다.

---

**Q4**. `스핀 락(spinlock)` 은 어떤 방식인가요? 뮤텍스와 어떻게 다른가요?

스핀락(Spinlock)도 상호 배제를 제공하지만, 일반적인 뮤텍스와는 동작 방식에 차이가 있습니다.

스핀락은 **잠금이 가능해질 때까지 스레드를 블로킹하지 않고, 반복문을 돌며 계속해서 잠금 상태를 확인**합니다. 말 그대로 스레드가 **돌면서 대기**하는 방식입니다.

이 방식은 **대기 시간이 매우 짧을 것으로 예상되는 경우에 유용**합니다. 왜냐하면 일반 뮤텍스처럼 스레드를 잠시 멈췄다가 다시 깨우는 과정(문맥 전환, context switching)은 오버헤드가 크기 때문에, 짧은 대기라면 오히려 **계속 CPU를 쓰면서 기다리는 것이 더 효율적**일 수 있기 때문입니다.

---

**Q4-1**. 어떨 때 스핀 락을 사용하면 안되나요?

**스핀락은 임계 영역의 실행 시간이 길어질 수 있거나,** 락을 보유한 스레드가 선점되어 중단될 가능성이 있는 경우에는 피하는 것이 좋습니다.

이런 상황에서는 잠금을 기다리는 스레드가 **불필요하게 CPU 자원을 소비하게 되기 때문입니다.**

---

**Q5. `세마포어(semaphore)` 에 대해 얘기해볼께요. 세마포어는 공유 자원을 어떻게 관리하나요?**

세마포어는 카운터를 사용해 자원 풀에 대한 접근을 제어합니다. 예를 들어, 세마포어가 3으로 초기화되어 있다면, 동시에 최대 3개의 스레드가 자원에 접근할 수 있다는 뜻입니다. `wait()` (또는 `P`)는 카운터를 감소시키고, `signal()` (또는 `V`)는 증가시킵니다. 이진 세마포어는 뮤텍스처럼 사용할 수도 있습니다.

---

**Q5-1. 세마포어로 데드락(교착 상태)을 방지할 수 있나요?**

세마포어 자체는 데드락을 방지하지 못합니다. 오히려 잘못 사용하면, 예를 들어 여러 개의 세마포어를 서로 다른 순서로 획득하는 경우, 데드락이 발생할 수 있습니다. 데드락 방지는 세마포어보다 **설계 방식**에 더 달려 있으며, 예를 들어 **자원 획득 순서를 정하거나, 타임아웃을 사용하는 방식**이 있습니다.

---

**Q6. 이제 `모니터(monitor)`에 대해 얘기해봅시다. 모니터란 무엇이며, 임계 영역과 어떤 관련이 있나요?**

**지원자:** 모니터는 공유 자원을 내부적으로 숨기고, 공유 자원에 접근하기 위한 인터페이스를 제공하는 구조입니다. 

뮤텍스와 세마포어는 개발자가 잘못 사용하면 너무 쉽게 오류가 발생하고, 경우에 따라 재현 가능하지 않습니다. 따라서 간단한 동기화 도구를 통합하는데 그것이 모니터입니다.

한 번에 하나의 스레드만 모니터 내부에서 실행될 수 있고, `wait()`와 `notify()` 같은 내장 메커니즘으로 스레드 간 협조를 지원합니다. Java의 `synchronized` 블록이나 Python의 `with threading.Lock()` 구문은 모니터와 유사한 기능을 합니다.

---

**Q6-1.** 모니터는 뮤텍스와 어떻게 다른가요?

뮤텍스는 **단순히 상호 배제**만 제공하는 **저수준 동기화 도구**입니다. 반면 모니터는 상호 배제뿐만 아니라 **조건을 기반으로 스레드가 대기하거나 알림을 받을 수 있는 기능**까지 포함합니다. 즉, 모니터는 공유 데이터와 동기화 로직을 함께 캡슐화하고 관리합니다.

# 질문 셋 3 - 캐시와 캐시 관리 전략

- 주제 제시

안녕하세요! CPU와 메모리 사이에서 사용되는 캐시에 대해서 얘기 나눠 봅시다.

---

**Q1. `캐시`가 무엇이고, 왜 사용하는지 간단히 설명해 주세요.**

캐시는 **자주 접근하는 데이터를 더 빠른 저장소에 저장하여, 이후 요청 시 빠르게 응답할 수 있도록 하는 기술**입니다. 주로 성능을 향상시키고 느린 시스템(예: 데이터베이스, 디스크 등)의 부담을 줄이기 위해 사용됩니다.

---

**Q2. 좋습니다. 일반적인 캐시 교체 정책을 아시는 대로 간단히 설명해 주시겠어요?**

- **LRU (Least Recently Used)** : 가장 오래 전에 사용된 데이터를 제거합니다.
- **LFU (Least Frequently Used)** : 가장 적게 사용된 데이터를 제거합니다.
- **FIFO (First In First Out)** : 가장 먼저 들어온 데이터를 제거합니다.

---

(Optional) **Q2-1**. Java에서 LRU 캐시를 구현한다고 가정하면, 어떻게 설계하시겠어요?

HashMap과 이중 연결 리스트(Doubly Linked List)를 조합해서 사용할 겁니다. HashMap은 키로 O(1)에 접근할 수 있고, 리스트는 사용 순서를 관리합니다. 데이터를 접근할 때마다 리스트의 앞쪽으로 옮기고, 캐시가 꽉 찼을 경우 리스트의 끝에서 데이터를 제거합니다.

---

**Q3. 캐시가 메모리보다 빠르다면 컴퓨터 메모리 전체를 캐시로 구성하면 안되나요?**

**속도와 비용은 반비례 관계**입니다. 캐시는 매우 빠르지만, 속도에 비례하여 **비용이 매우 비쌉니다**. 즉, CPU 캐시처럼 빠르고 작은 메모리는 매우 고가이고, 대량으로 확장하는 데는 경제적이지 않습니다.

캐시는 매우 작은 용량으로 설계됩니다. **작은 데이터 집합에 대해서 빠르게 접근**할 수 있지만, 모든 데이터를 캐시로 저장할 만큼 큰 용량을 처리하기에는 한계가 있습니다.

---

**Q4. 캐시와 관련해서, 프로그램이 데이터를 참조할 때 `지역성`이라는 개념이 있는데요? 지역성에 대해 설명해주실 수 있나요?**

- **시간적 지역성 (Temporal locality)**: 최근에 접근한 데이터는 가까운 미래에 다시 접근할 가능성이 높다는 개념입니다. 즉, 한 번 사용된 데이터는 계속해서 사용할 확률이 높기 때문에 이를 캐시하여 빠르게 접근할 수 있습니다.
- **공간적 지역성 (Spatial locality)**: 근처의 데이터도 함께 접근할 가능성이 높다는 개념입니다. 예를 들어, 배열에서 인덱스 0을 접근한 후 인덱스 1, 2 등도 차례로 접근할 가능성이 크므로, 인접 데이터를 함께 캐시하는 방식입니다.

# 질문 셋 4 - 프로세스 생성

- 주제 제시

이번엔 운영체제에서 프로세스를 어떻게 생성하는지와 관련해서 얘기해봅시다.

---

**Q1. 새로운 프로세스를 만들 때 어떤 시스템 콜이 사용되는지 아시나요? 아시면 간단히 설명해주시겠어요?**

시스템 콜인 `fork()`를 호출하면 현재 실행 중인 프로세스를 복제하여 새로운 자식 프로세스를 생성합니다.

`exec()` 시스템 콜은 자식 프로세스가 `fork`로 생성된 후, 그 프로세스에서 새로운 프로그램을 실행하도록 합니다. `exec`는 현재 프로세스의 메모리 공간을 새로운 프로그램의 코드로 덮어쓰며, 기존의 실행 중인 프로그램을 종료하고 새로운 프로그램을 실행합니다.

---

**Q2**. `fork()` 시스템 콜이 호출되면 바로 부모 프로세스의 메모리 공간 복사가 일어나나요?

`fork` 시스템 콜을 호출할 때, 자식 프로세스는 부모 프로세스의 메모리 공간을 복사하지만, 실제로 메모리 복사는 즉시 이루어지지 않습니다. 이 방식은 **Copy-on-Write (COW)** 기법을 사용하여 성능을 최적화합니다.

1. **가상 메모리 복사**: `fork`가 호출되면, 운영 체제는 부모 프로세스의 메모리 공간을 자식 프로세스와 공유하도록 설정합니다. 이때, 부모와 자식 프로세스는 동일한 물리적 메모리 페이지를 참조합니다.
2. **Copy-on-Write (COW)**: 부모와 자식 프로세스는 처음에는 메모리 페이지를 복사하지 않습니다. 대신, 각 프로세스가 해당 페이지를 수정하려고 할 때, 운영 체제는 그 시점에서 메모리 페이지를 복사합니다. 즉, **쓰기 작업이 일어날 때**에만 복사가 발생하는 방식입니다. 이를 통해 메모리 사용을 최소화하고 성능을 향상시킬 수 있습니다.

---

**Q3**. `고아 프로세스`에 대해 아시나요? 고아 프로세스에 대해 간단히 설명해주세요.

고아 프로세스는 부모 프로세스가 먼저 종료된 자식 프로세스입니다.

유닉스/리눅스 계열 시스템에서는 고아가 된 프로세스를 자동으로 **`init` 프로세스(PID 1)** 또는 **`systemd`**가 "양자"로 받아들입니다.

---

**Q4**. 그럼 `좀비 프로세스`는 무엇인가요?

좀비 프로세스는 **실제로는 종료되었지만, 여전히 프로세스 테이블에 남아 있는 프로세스**입니다.

자식 프로세스가 종료됐지만, 부모 프로세스가 아직 그 자식의 종료 상태를 `wait()` 또는 `waitpid()`로 수거하지 않았을 때 생깁니다. 이 프로세스는 실제로는 종료되었지만, 프로세스 테이블에 남아있는 상태입니다

---

**Q5**. 좀비 프로세스가 너무 많아질 경우 어떤 문제가 생길 수 있나요?

좀비는 프로세스 테이블 항목을 차지하기 때문에, 너무 많아지면 새로운 프로세스를 만들 수 없게 됩니다. 결국 시스템 자원을 고갈시키는 문제가 생깁니다.
